{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorizing places into subcategories by the terms in place_description\n",
    "import pandas as pd\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('Places.csv')\n",
    "\n",
    "# Preprocess the data\n",
    "data.dropna(subset=['Place', 'Place_desc'], inplace=True)  # Remove rows with missing data\n",
    "data['Place'] = data['Place'].str.lower()  # Convert place names to lowercase\n",
    "data['Place_desc'] = data['Place_desc'].str.lower()  # Convert place descriptions to lowercase\n",
    "\n",
    "# Define the list of keywords\n",
    "keywords = [\n",
    "    \"adventure\",\n",
    "    \"scenic\",\n",
    "    \"wildlife\",\n",
    "    \"cultural\",\n",
    "    \"religious\",\n",
    "    \"urban\",\n",
    "    \"rural\",\n",
    "    \"coastal\",\n",
    "    \"historic\",\n",
    "    \"archaeological\",\n",
    "    \"natural\",\n",
    "    \"ecological\",\n",
    "    \"botanical\",\n",
    "    \"geological\",\n",
    "    \"artistic\",\n",
    "    \"architectural\",\n",
    "    \"food\",\n",
    "    \"shopping\",\n",
    "    \"entertainment\",\n",
    "    \"nightlife\",\n",
    "    \"hiking\",\n",
    "    \"camping\",\n",
    "    \"trekking\",\n",
    "    \"safari\",\n",
    "    \"water sports\",\n",
    "    \"skiing\",\n",
    "    \"cycling\",\n",
    "    \"birdwatching\",\n",
    "    \"botanical gardens\",\n",
    "    \"national parks\",\n",
    "    \"museums\",\n",
    "    \"monuments\",\n",
    "    \"temples\",\n",
    "    \"mosques\",\n",
    "    \"churches\",\n",
    "    \"palaces\",\n",
    "    \"forts\",\n",
    "    \"ruins\",\n",
    "    \"lakes\",\n",
    "    \"rivers\",'Mountains','Mountain roads, Tunnels' 'Hill stations', 'Tea gardens', 'Spice plantations', 'Beaches', 'Backwaters', 'Waterfalls', 'Deserts', 'Plains', 'Islands', 'Jungles', 'Sanctuaries', 'Reserves', 'Festivals', 'Fairs', 'Carnivals', 'Dance forms', 'Music', 'Cuisine', 'Handicrafts', 'Textiles', 'Pottery', 'Sculptures', 'Paintings', 'Folklore', 'Legends', 'Mythology', 'Traditions', 'Customs', 'Rituals', 'Yoga', 'Meditation', 'Ayurveda', 'Wellness', 'Spiritual', 'Religious ceremonies', 'Pilgrimages', 'Ashrams', 'Gurudwaras', 'Synagogues', 'Citadel', 'Bastions', 'Ramparts', 'Gateways', 'Courtyards', 'Havelis', 'Mansions', 'Bungalows', 'Villas', 'Residences', 'Homestays', 'Guesthouses', 'Inns', 'Lodges', 'Accommodations','Scenic drives', 'Road trips', 'Motorcycling', 'Rock climbing', 'Mountaineering', 'Paragliding', 'Mountain biking', 'Zip-lining', 'Cable car rides', 'Sightseeing', 'Photography', 'Stargazing', 'Picnicking', 'Exploring', 'Nature walks', 'Wildlife spotting', 'Fishing', 'Whitewater rafting', 'Kayaking', 'Canoeing', 'Off-roading', 'Adventure tours', 'Horseback riding', 'Hot air ballooning', 'Helicopter tours', 'Sledging', 'Ice climbing', 'Snowshoeing', 'Snowboarding', 'Cross-country skiing', 'Glacier walking', 'Mushing', 'Dog sledding', 'Heli-skiing', 'Snowmobiling', 'Avalanche safety training', 'Ski jumping', 'Snow tubing', 'Ice skating', 'Ice fishing', 'Ice diving', 'Ice climbing', 'Ice sailing', 'Ice golfing', 'Ice kayaking', 'Ice swimming', 'Ice boating', 'Snow sculpture festivals', 'Winter carnivals', 'Christmas markets', 'Fireworks displays', 'Winter sports competitions', 'Après-ski parties', 'Snowman building contests', 'Winter picnics', 'Winter solstice celebrations', 'Ice hotels', 'Winter festivals''Scenic drives', 'Road trips', 'Motorcycling', 'Rock climbing', 'Mountaineering', 'Paragliding', 'Mountain biking', 'Zip-lining', 'Cable car rides', 'Sightseeing', 'Photography', 'Stargazing', 'Picnicking', 'Exploring', 'Nature walks', 'Wildlife spotting', 'Fishing', 'Whitewater rafting', 'Kayaking', 'Canoeing', 'Off-roading', 'Adventure tours', 'Horseback riding', 'Hot air ballooning', 'Helicopter tours', 'Sledging', 'Ice climbing', 'Snowshoeing', 'Snowboarding', 'Cross-country skiing', 'Glacier walking', 'Mushing', 'Dog sledding', 'Heli-skiing', 'Snowmobiling', 'Avalanche safety training', 'Ski jumping', 'Snow tubing', 'Ice skating', 'Ice fishing', 'Ice diving', 'Ice climbing', 'Ice sailing', 'Ice golfing', 'Ice kayaking', 'Ice swimming', 'Ice boating', 'Snow sculpture festivals', 'Winter carnivals', 'Christmas markets', 'Fireworks displays', 'Winter sports competitions', 'Après-ski parties', 'Snowman building contests', 'Winter picnics', 'Winter solstice celebrations', 'Ice hotels', 'Winter festivals'\n",
    "]\n",
    "\n",
    "# Function to find synonyms of a word\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().lower())\n",
    "    return synonyms\n",
    "\n",
    "# Generate a set of all synonyms of the keywords\n",
    "all_keywords = set()\n",
    "for keyword in keywords:\n",
    "    all_keywords.add(keyword)\n",
    "    all_keywords |= get_synonyms(keyword)\n",
    "\n",
    "# Initialize a list to store predicted types for each row\n",
    "predicted_types = []\n",
    "\n",
    "# Prioritize classification based on keywords in place names\n",
    "for index, row in data.iterrows():\n",
    "    row_predicted_types = []\n",
    "    for keyword in all_keywords:\n",
    "        if keyword in row['Place'] or keyword in row['Place_desc']:\n",
    "            row_predicted_types.append(keyword)\n",
    "    predicted_types.append(row_predicted_types)\n",
    "\n",
    "# Convert list of lists to a single list of unique types\n",
    "all_predicted_types = set([item for sublist in predicted_types for item in sublist])\n",
    "\n",
    "# Add a new column for the predicted types in the dataset\n",
    "data['Predicted_Types'] = [', '.join(types) for types in predicted_types]\n",
    "\n",
    "# Save the updated dataset\n",
    "data.to_csv('New_Places.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b26d626",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Define categories and their corresponding keywords\n",
    "categories = {\n",
    "    \"Adventure\": ['Hiking', 'Camping', 'Trekking', 'Safari', 'Water sports', 'Skiing', 'Cycling', 'Birdwatching', 'Botanical gardens', 'National parks', 'Scenic drives', 'Road trips', 'Motorcycling', 'Rock climbing', 'Mountaineering', 'Paragliding', 'Mountain biking', 'Zip-lining', 'Cable car rides', 'Sightseeing', 'Photography', 'Stargazing', 'Picnicking', 'Exploring', 'Nature walks', 'Wildlife spotting', 'Fishing', 'Whitewater rafting', 'Kayaking', 'Canoeing', 'Off-roading', 'Adventure tours', 'Horseback riding', 'Hot air ballooning', 'Helicopter tours', 'Sledging', 'Ice climbing', 'Snowshoeing', 'Snowboarding', 'Cross-country skiing', 'Glacier walking', 'Mushing', 'Dog sledding', 'Heli-skiing', 'Snowmobiling', 'Avalanche safety training', 'Ski jumping', 'Snow tubing', 'Ice skating', 'Ice fishing', 'Ice diving', 'Ice sailing', 'Ice golfing', 'Ice kayaking', 'Ice swimming', 'Ice boating', 'Snow sculpture festivals', 'Winter carnivals', 'Christmas markets', 'Fireworks displays', 'Winter sports competitions', 'Après-ski parties', 'Snowman building contests', 'Winter picnics', 'Winter solstice celebrations', 'Ice hotels', 'Winter festivals'],\n",
    "    \"Scenic\": ['Scenic', 'Scenic drives', 'Road trips', 'Sightseeing', 'Photography', 'Stargazing', 'Picnicking', 'Exploring', 'Nature walks', 'Wildlife spotting', 'Lakes', 'Rivers', 'Mountains', 'Mountain roads', 'Tunnels', 'Hill stations', 'Tea gardens', 'Spice plantations', 'Beaches', 'Backwaters', 'Waterfalls', 'Deserts', 'Plains', 'Islands', 'Jungles', 'Sanctuaries', 'Reserves'],\n",
    "    \"Cultural\": [\"cultural\", \"historical\", \"archaeological\", \"artistic\", \"religion\", \"temples\", \"mosques\", \"churches\", \"palaces\", \"forts\", \"ruins\", \"museums\", \"monuments\", \"folklore\", \"legends\", \"mythology\", \"traditions\", \"customs\", \"rituals\", \"festivals\", \"fairs\", \"carnivals\", \"dance forms\", \"music\"],\n",
    "    \"Food\": [\"food\", \"cuisine\"],\n",
    "    \"Shopping\": [\"shopping\"],\n",
    "    \"Entertainment\": [\"entertainment\", \"nightlife\"],\n",
    "    \"Water Sports\": [\"water sports\", \"fishing\", \"whitewater rafting\", \"kayaking\", \"canoeing\"],\n",
    "    \"Mountain Activities\": [\"mountains\", \"hill stations\", \"mountain roads\", \"tea gardens\", \"spice plantations\", \"skiing\", \"cycling\", \"birdwatching\", \"botanical gardens\", \"national parks\", \"lakes\", \"rivers\", \"backwaters\", \"waterfalls\", \"deserts\", \"plains\", \"islands\", \"jungles\", \"sanctuaries\", \"reserves\"],\n",
    "    \"Wellness\": [\"yoga\", \"meditation\", \"ayurveda\", \"wellness\", \"spiritual\", \"religious ceremonies\", \"pilgrimages\", \"ashrams\", \"gurudwaras\", \"synagogues\"],\n",
    "    \"Architecture\": [\"architectural\", \"gateways\", \"courtyards\", \"havelis\", \"mansions\", \"bungalows\", \"villas\", \"residences\", \"homestays\", \"guesthouses\", \"inns\", \"lodges\", \"accommodations\", \"citadel\", \"bastions\", \"ramparts\"],\n",
    "    \"Beaches\": [\"beaches\", \"coastal\", \"islands\"],\n",
    "    \"Deserts\": [\"deserts\"],\n",
    "    \"Forests\": [\"forests\", \"jungles\", \"sanctuaries\", \"reserves\"],\n",
    "    \"Historic Sites\": [\"historical sites\", \"archaeological sites\", \"monuments\", \"ruins\"],\n",
    "    \"Art and Culture\": [\"art\", \"culture\", \"museums\", \"galleries\", \"performing arts\"],\n",
    "    \"Religious Sites\": [\"temples\", \"mosques\", \"churches\", \"shrines\"],\n",
    "    \"Adventure Sports\": [\"adventure sports\", \"extreme sports\", \"water sports\", \"snow sports\"],\n",
    "    \"Family-Friendly\": [\"family-friendly\", \"kids-friendly\", \"amusement parks\", \"zoo\", \"aquarium\"],\n",
    "    \"Shopping\": [\"shopping\", \"markets\", \"boutiques\"],\n",
    "    \"Wellness\": [\"wellness\", \"spa\", \"health retreats\", \"meditation centers\", \"yoga retreats\"],\n",
    "    \"Offbeat\": [\"offbeat\", \"lesser-known\", \"hidden gems\", \"unexplored\"],\n",
    "    # Add more categories as needed\n",
    "    # Indian tourists\n",
    "    \"Spiritual Journeys\": [\"spiritual\", \"religious ceremonies\", \"pilgrimages\", \"ashrams\", \"gurudwaras\", \"yoga\", \"meditation\", \"ayurveda\"],\n",
    "    \"Festivals and Events\": [\"festivals\", \"fairs\", \"carnivals\"],\n",
    "    \"Historical and Architectural Marvels\": [\"historical\", \"archaeological\", \"architectural\", \"temples\", \"mosques\", \"churches\", \"palaces\", \"forts\", \"ruins\"],\n",
    "    \"Nature and Wildlife\": [\"natural\", \"ecological\", \"botanical\", \"geological\", \"national parks\", \"lakes\", \"rivers\", \"backwaters\", \"waterfalls\", \"deserts\", \"plains\", \"islands\", \"jungles\", \"sanctuaries\", \"reserves\"],\n",
    "    \"Adventure and Trekking\": [\"adventure\", \"trekking\", \"camping\", \"safari\", \"hiking\", \"mountaineering\", \"rock climbing\", \"paragliding\", \"zip-lining\", \"whitewater rafting\", \"kayaking\", \"canoeing\", \"off-roading\", \"horseback riding\", \"hot air ballooning\", \"helicopter tours\", \"sledging\", \"ice climbing\", \"snowboarding\", \"cross-country skiing\", \"glacier walking\", \"mushing\", \"dog sledding\", \"heli-skiing\", \"snowmobiling\", \"ski jumping\", \"snow tubing\", \"ice skating\", \"ice diving\", \"ice sailing\", \"ice golfing\", \"ice kayaking\", \"ice swimming\", \"ice boating\", \"snow sculpture festivals\", \"winter carnivals\", \"fireworks displays\", \"winter sports competitions\", \"après-ski parties\", \"snowman building contests\", \"winter picnics\", \"winter solstice celebrations\", \"ice hotels\", \"winter festivals\"],\n",
    "    # Foreign tourists\n",
    "    \"Cultural Immersion\": [\"cultural\", \"artistic\", \"folklore\", \"legends\", \"mythology\", \"traditions\", \"customs\", \"rituals\", \"dance forms\", \"music\"],\n",
    "    \"Culinary Experiences\": [\"food\", \"cuisine\"],\n",
    "    \"Luxury and Wellness Retreats\": [\"wellness\", \"spa\", \"health retreats\"],\n",
    "    \"Offbeat and Eco-Tourism\": [\"offbeat\", \"lesser-known\", \"hidden gems\", \"unexplored\"],\n",
    "    \"Beach Holidays\": [\"beaches\", \"coastal\", \"islands\"]\n",
    "}\n",
    "\n",
    "# Flatten the categories dictionary for easier keyword lookup\n",
    "keyword_to_category = {keyword.lower(): category for category, keywords in categories.items() for keyword in keywords}\n",
    "\n",
    "# Function to classify multiple keywords\n",
    "def classify_multiple_keywords(predicted_types):\n",
    "    if pd.isnull(predicted_types):\n",
    "        return \"Other\"\n",
    "    \n",
    "    keywords = predicted_types.split(', ')\n",
    "    classified_categories = []\n",
    "\n",
    "    for keyword in keywords:\n",
    "        keyword_lower = keyword.lower()\n",
    "        category = keyword_to_category.get(keyword_lower, \"Other\")\n",
    "        classified_categories.append(category)\n",
    "    \n",
    "    # Count the frequency of each category and return the most common one\n",
    "    most_common_category = Counter(classified_categories).most_common(1)[0][0]\n",
    "    \n",
    "    return most_common_category\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('testcat.csv', encoding='latin-1')\n",
    "\n",
    "# Apply the classification function to each row in the dataframe\n",
    "df['Category'] = df['Predicted_Types'].apply(classify_multiple_keywords)\n",
    "\n",
    "# Save the updated dataframe to a new CSV file\n",
    "df.to_csv('Classified_New_Places1.csv', index=False, encoding='latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66c9ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEB SCRAPING\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('updated_dataset_in_progress1.csv', encoding='latin-1')\n",
    "\n",
    "# Initialize a new column for votes if not present\n",
    "if 'votes' not in df.columns:\n",
    "    df['votes'] = None\n",
    "\n",
    "# Set up Selenium WebDriver\n",
    "driver = webdriver.Chrome()  # Ensure that chromedriver is in your PATH\n",
    "\n",
    "def get_votes_from_google_maps(latitude, longitude):\n",
    "    search_url = f\"https://www.google.com/maps/@{latitude},{longitude},15z\"\n",
    "    \n",
    "    driver.get(search_url)\n",
    "    time.sleep(5)  # Wait for the page to load\n",
    "\n",
    "    # Check if a CAPTCHA is present\n",
    "    if \"sorry\" in driver.current_url.lower():\n",
    "        print(\"CAPTCHA encountered. Please solve it manually.\")\n",
    "        while \"sorry\" in driver.current_url.lower():\n",
    "            time.sleep(15)  # Wait and allow the user to solve the CAPTCHA\n",
    "\n",
    "    try:\n",
    "        # Use BeautifulSoup to parse the page\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        votes_element = soup.find('span', {'aria-label': lambda x: x and 'reviews' in x})\n",
    "        if votes_element:\n",
    "            votes = votes_element.text.strip(\"()\").replace(\",\", \"\")\n",
    "            return votes\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve data for coordinates ({latitude}, {longitude}): {e}\")\n",
    "        return None\n",
    "\n",
    "# Start index and limit for requests\n",
    "start_index = 0  # Set this to your starting index\n",
    "max_requests = 150  # Limit for the number of requests\n",
    "\n",
    "# Iterate through the dataset and update votes\n",
    "try:\n",
    "    for index in range(start_index, min(start_index + max_requests, len(df))):\n",
    "        row = df.iloc[index]\n",
    "        if pd.isna(row['votes']):\n",
    "            latitude = row['latitude']  # Adjust this column name as per your dataset\n",
    "            longitude = row['longitude']  # Adjust this column name as per your dataset\n",
    "            print(f\"Processing coordinates ({latitude}, {longitude}) at index {index}\")\n",
    "            \n",
    "            votes = get_votes_from_google_maps(latitude, longitude)\n",
    "            if votes:\n",
    "                df.at[index, 'votes'] = votes\n",
    "                print(f\"Successfully retrieved data for coordinates ({latitude}, {longitude}): Votes - {votes}\")\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data for coordinates ({latitude}, {longitude})\")\n",
    "\n",
    "            # Save progress after each request to avoid losing data in case of interruptions\n",
    "            df.to_csv('updated_dataset_in_progress.csv', index=False)\n",
    "\n",
    "            # Sleep for a random duration between 5 and 10 seconds to comply with rate limiting\n",
    "            sleep_duration = random.uniform(5, 10)\n",
    "            print(f\"Sleeping for {sleep_duration:.2f} seconds\")\n",
    "            time.sleep(sleep_duration)\n",
    "finally:\n",
    "    # Save the updated dataset in case of any interruption\n",
    "    df.to_csv('updated_dataset_in_progress1.csv', index=False)\n",
    "    # Close the WebDriver\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75683f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('Placestestf.csv', encoding='latin-1')\n",
    "\n",
    "# Ensure your dataset has the necessary columns\n",
    "required_columns = ['City', 'Place_Name', 'latitude', 'longitude', 'Ratings', 'votes', 'Categories', 'Place_desc']\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "# Drop rows with missing coordinates\n",
    "df = df.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# Handle missing values in Ratings and votes by filling with a default value\n",
    "df['Ratings'].fillna(0, inplace=True)\n",
    "df['votes'].fillna(0, inplace=True)\n",
    "\n",
    "# Function to calculate the weight based on ratings and votes\n",
    "def calculate_weight(row):\n",
    "    if row['Ratings'] > 0 and row['votes'] > 0:\n",
    "        return (row['Ratings'] + (row['votes'] / 1000)) / 2  # Aggregate by averaging\n",
    "    elif row['Ratings'] > 0:\n",
    "        return row['Ratings']\n",
    "    elif row['votes'] > 0:\n",
    "        return row['votes'] / 1000  # Scale votes down\n",
    "    else:\n",
    "        return 0  # Default value if both are missing\n",
    "\n",
    "df['Weight'] = df.apply(calculate_weight, axis=1)\n",
    "\n",
    "# Min-max normalization to scale weights between 2.5 and 3.5\n",
    "min_weight = df['Weight'].min()\n",
    "max_weight = df['Weight'].max()\n",
    "\n",
    "df['Score'] = 2.5 + (df['Weight'] - min_weight) * (3.5 - 2.5) / (max_weight - min_weight)\n",
    "\n",
    "# Function to match categories\n",
    "def match_categories(categories_string, selected_categories):\n",
    "    if pd.isna(categories_string):\n",
    "        return False\n",
    "    categories_list = categories_string.split(',')\n",
    "    for category in categories_list:\n",
    "        if any(cat.strip().lower() in category.strip().lower() for cat in selected_categories):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to recommend places\n",
    "def recommend_places(city, categories, num_days, places_per_day):\n",
    "    # Filter places for the specified city\n",
    "    city_places = df[df['City'] == city]\n",
    "    city_places = city_places.sort_values(by=['Score'], ascending=False)\n",
    "\n",
    "    # Filter places based on user-specified categories\n",
    "    primary_places = city_places[city_places['Categories'].apply(lambda x: match_categories(str(x), categories))]\n",
    "    secondary_places = city_places[~city_places['Categories'].apply(lambda x: match_categories(str(x), categories))]\n",
    "    \n",
    "    # Combine primary and secondary places\n",
    "    combined_places = pd.concat([primary_places, secondary_places]).drop_duplicates(subset=['Place_Name'])\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    k = 5  # Adjust based on your requirements\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    combined_places['Cluster'] = kmeans.fit_predict(combined_places[['latitude', 'longitude']])\n",
    "    \n",
    "    # Plot the clusters (optional)\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(combined_places['longitude'], combined_places['latitude'], c=combined_places['Cluster'], cmap='viridis', marker='o')\n",
    "    plt.colorbar(label='Cluster')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title(f'K-Means Clustering of Places in {city}')\n",
    "    plt.show()\n",
    "\n",
    "    # Group by clusters to ensure diversity\n",
    "    clusters = combined_places.groupby('Cluster')\n",
    "\n",
    "    # Create itinerary\n",
    "    itinerary = []\n",
    "    selected_indices = set()  # To keep track of selected places to avoid duplicates\n",
    "    for day in range(num_days):\n",
    "        daily_itinerary = []\n",
    "        for cluster_id, cluster_data in clusters:\n",
    "            cluster_places = cluster_data[~cluster_data['Place_Name'].isin(selected_indices)].head(places_per_day)\n",
    "            daily_itinerary.extend(cluster_places.to_dict('records'))\n",
    "            selected_indices.update(cluster_places['Place_Name'])\n",
    "            if len(daily_itinerary) >= places_per_day:\n",
    "                break\n",
    "        itinerary.append(daily_itinerary[:places_per_day])  # Ensure we only take the desired number of places\n",
    "\n",
    "        # Drop the selected places to avoid duplicates in subsequent days\n",
    "        combined_places = combined_places[~combined_places['Place_Name'].isin(selected_indices)]\n",
    "\n",
    "        # Update clusters after dropping the selected places\n",
    "        clusters = combined_places.groupby('Cluster')\n",
    "\n",
    "    return itinerary\n",
    "\n",
    "# Take user inputs\n",
    "city = input(\"Enter the city name: \")\n",
    "\n",
    "# Display available categories in the city\n",
    "available_categories = df[df['City'] == city]['Categories'].dropna().unique()\n",
    "available_categories = [cat.strip() for sublist in available_categories for cat in sublist.split(',')]\n",
    "available_categories = list(set(available_categories))  # Get unique categories\n",
    "print(\"Available categories in the city:\", ', '.join(available_categories))\n",
    "\n",
    "# Ensure user selects valid categories\n",
    "selected_categories = []\n",
    "while not selected_categories:\n",
    "    categories = input(\"Enter categories (comma-separated) from the above list: \").split(',')\n",
    "    selected_categories = [cat.strip() for cat in categories if cat.strip() in available_categories]\n",
    "    if not selected_categories:\n",
    "        print(\"Please select valid categories from the list provided.\")\n",
    "\n",
    "places_per_day = int(input(\"Enter the number of places per day: \"))\n",
    "\n",
    "# Calculate the maximum number of days\n",
    "total_places = df[(df['City'] == city) & (df['Categories'].apply(lambda x: match_categories(str(x), selected_categories)))].shape[0]\n",
    "max_days = -(-total_places // places_per_day)  # Ceiling division\n",
    "print(f\"Based on {places_per_day} places per day, you can cover the places in a maximum of {max_days} days.\")\n",
    "\n",
    "num_days = int(input(f\"Enter the number of days (max {max_days}): \"))\n",
    "if num_days > max_days:\n",
    "    print(f\"You requested more days than the recommended maximum of {max_days} days.\")\n",
    "    print(\"You will be provided with the top places based on weight for the additional days.\")\n",
    "    \n",
    "    # Ask user for additional categories only once\n",
    "    additional_categories = input(\"Enter additional categories (comma-separated) from the available list or press Enter to skip: \").split(',')\n",
    "    additional_categories = [cat.strip() for cat in additional_categories if cat.strip() in available_categories]\n",
    "    \n",
    "    if additional_categories:\n",
    "        selected_categories.extend(additional_categories)\n",
    "        total_places = df[(df['City'] == city) & (df['Categories'].apply(lambda x: match_categories(str(x), selected_categories)))].shape[0]\n",
    "        max_days = -(-total_places // places_per_day)  # Ceiling division\n",
    "        print(f\"Based on {places_per_day} places per day, you can now cover the places in a maximum of {max_days} days.\")\n",
    "    \n",
    "    # Adjust num_days if additional categories increased the max_days\n",
    "    num_days = int(input(f\"Enter the number of days (max {max_days}): \"))\n",
    "\n",
    "# Generate the initial itinerary\n",
    "itinerary = recommend_places(city, selected_categories, min(num_days, max_days), places_per_day)\n",
    "\n",
    "# If the user requested more days, add top weighted places for the extra days\n",
    "if num_days > max_days:\n",
    "    additional_days = num_days - max_days\n",
    "    top_places = df[df['City'] == city].sort_values(by='Weight', ascending=False).drop_duplicates(subset=['Place_Name'])\n",
    "    additional_itinerary = []\n",
    "    selected_indices = set([place['Place_Name'] for day in itinerary for place in day])  # Update with already selected places\n",
    "    for day in range(additional_days):\n",
    "        daily_itinerary = top_places[~top_places['Place_Name'].isin(selected_indices)].head(places_per_day).to_dict('records')\n",
    "        additional_itinerary.append(daily_itinerary)\n",
    "        selected_indices.update([place['Place_Name'] for place in daily_itinerary])\n",
    "    itinerary.extend(additional_itinerary)\n",
    "\n",
    "# Display the itinerary\n",
    "for day, daily_itinerary in enumerate(itinerary, start=1):\n",
    "    print(f\"Day {day}:\")\n",
    "    for place in daily_itinerary:\n",
    "        print(f\"  {place['Place_Name']} - {place['Categories']} - Rating: {place['Ratings']} - Votes: {place['votes']} - Score: {place['Score']} - Latitude: {place['latitude']} - Longitude: {place['longitude']} - Description: {place['Place_desc']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
